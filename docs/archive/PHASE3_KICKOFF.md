# Phase 3: GPU Kernel Optimization - Kickoff Document

**Date:** November 17, 2025
**Status:** ‚úÖ READY TO BEGIN
**Baseline Performance:** 572-757M words/s (RTX 4070 Ti SUPER)
**Target:** 1B+ words/s (50-75% improvement)

---

## Executive Summary

Phase 2.6 validation is complete with publication-ready results. We now begin Phase 3: systematic GPU kernel optimization to push toward 1B+ words/s throughput.

**Current State:**
- ‚úÖ Baseline benchmarks complete (Nov 17, 2025)
- ‚úÖ All patterns stable (CV < 5%)
- ‚úÖ Mathematical correctness proven
- ‚úÖ Statistical validation complete
- üéØ Ready for optimization

**Baseline Performance (Nov 17, 2025):**
- small_4char_lowercase: 737M words/s (¬±2.96%)
- medium_6char_lowercase: 750M words/s (¬±2.19%)
- large_8char_lowercase: 584M words/s (¬±0.66%)
- mixed_upper_lower_digits: 587M words/s (¬±0.71%)
- special_chars: 763M words/s (¬±0.61%)

**Average: ~684M words/s across all patterns**

---

## Phase 3 Optimization Strategy

### Priority 1: Arithmetic Optimization (High Impact)
**Current bottleneck:** Integer division and modulo operations

#### Optimization 3.1: Barrett Reduction
**What:** Replace `x % m` and `x / m` with fast multiplication-based approximation
**Expected gain:** 20-40% throughput improvement
**Complexity:** Medium (2-3 days implementation)
**Risk:** Low (well-established algorithm)

**Implementation plan:**
1. Precompute Barrett constants for each charset size
2. Replace modulo: `x % m` ‚Üí `x - (x * m_inv >> shift) * m`
3. Replace division: `x / m` ‚Üí `(x * m_inv) >> shift`
4. Benchmark before/after with `scripts/compare_benchmarks.sh`

**Files to modify:**
- `kernels/wordlist_poc.cu` (lines 44-46, 85-87)
- `src/gpu/mod.rs` (add precomputation)

#### Optimization 3.2: Power-of-2 Fast Path
**What:** Special case for charset sizes that are powers of 2 (use bitwise ops)
**Expected gain:** 50%+ for power-of-2 charsets (common case: 64 chars = 2^6)
**Complexity:** Low (1 day)
**Risk:** Very low

**Implementation:**
```cuda
if (is_power_of_2(cs_size)) {
    int char_idx = remaining & (cs_size - 1);  // Fast modulo
    remaining >>= log2_size;                    // Fast division
} else {
    // Barrett reduction fallback
}
```

### Priority 2: Memory Optimization (Medium-High Impact)
**Current state:** Global memory writes are coalesced, but can be improved

#### Optimization 3.3: Shared Memory for Charsets
**What:** Load frequently-accessed charset data into shared memory
**Expected gain:** 10-15% (reduce global memory traffic)
**Complexity:** Medium (2 days)
**Risk:** Low

#### Optimization 3.4: Pinned Memory for Transfers
**What:** Use CUDA pinned memory for faster CPU‚ÜîGPU transfers
**Expected gain:** 5-10% (reduce transfer latency)
**Complexity:** Low (1 day)
**Risk:** Very low

### Priority 3: Occupancy Tuning (Medium Impact)
**Current state:** Unknown (need profiling data)

#### Optimization 3.5: Block Size Tuning
**What:** Experiment with thread block sizes (128, 256, 512, 1024)
**Expected gain:** 5-15% (maximize warp utilization)
**Complexity:** Low (automated search)
**Risk:** None (pure experimentation)

#### Optimization 3.6: Register Pressure Reduction
**What:** Reduce local variable usage to increase occupancy
**Expected gain:** 0-10% (depends on current register usage)
**Complexity:** Medium (requires profiling)
**Risk:** Low

### Priority 4: Advanced Optimizations (Lower Priority)
**Defer until basic optimizations complete**

#### Optimization 3.7: Asynchronous Transfers with CUDA Streams
**What:** Overlap compute with data transfer
**Expected gain:** 10-20% (hide latency)
**Complexity:** High (3-4 days)

#### Optimization 3.8: Multi-GPU Support
**What:** Distribute keyspace across multiple GPUs
**Expected gain:** Linear scaling (2x GPUs = 2x throughput)
**Complexity:** High (5-7 days)

---

## Profiling Setup

### Current Status: ‚ö†Ô∏è Needs Permission Fix

**Issue:** `ERR_NVGPUCTRPERM` - GPU performance counters require admin access

**Fix (requires reboot):**
```bash
sudo tee /etc/modprobe.d/nvidia-profiling.conf <<EOF
options nvidia NVreg_RestrictProfilingToAdminUsers=0
EOF
sudo reboot
```

**After reboot, verify:**
```bash
cat /proc/driver/nvidia/params | grep RmProfilingAdminOnly
# Should show: RmProfilingAdminOnly: 0
```

**Then run profiling:**
```bash
./scripts/profile_kernel.sh
```

### What Profiling Will Tell Us

1. **Compute vs Memory Bound:**
   - If compute-bound: Focus on arithmetic (Barrett, power-of-2)
   - If memory-bound: Focus on memory optimizations (shared mem, coalescing)

2. **Occupancy:**
   - Current: Unknown
   - Target: >50% (higher is better)
   - If low: Reduce register usage, tune block size

3. **Instruction Mix:**
   - How many div/mod operations per word?
   - How expensive are they? (multi-cycle stalls?)

4. **Memory Access Patterns:**
   - Are global reads/writes coalesced?
   - Cache hit rates?

---

## Phase 3 Execution Plan

### Week 1: Arithmetic Optimizations (Barrett + Power-of-2)

**Day 1-2: Barrett Reduction**
- [ ] Research Barrett reduction for CUDA
- [ ] Implement precomputation in Rust (calculate constants)
- [ ] Modify kernel to use Barrett reduction
- [ ] Run benchmarks, compare with baseline
- [ ] Target: +20-40% throughput

**Day 3: Power-of-2 Fast Path**
- [ ] Add power-of-2 detection
- [ ] Implement bitwise fast path in kernel
- [ ] Benchmark with power-of-2 charsets
- [ ] Target: +50% for power-of-2 cases

**Day 4: Integration Testing**
- [ ] Run full benchmark suite
- [ ] Validate correctness (cross-validate with CPU)
- [ ] Update baseline with optimized results
- [ ] Create memory entry for progress

### Week 2: Memory & Occupancy Optimizations

**Day 5: Shared Memory for Charsets**
- [ ] Modify kernel to use shared memory
- [ ] Benchmark impact
- [ ] Target: +10-15%

**Day 6: Pinned Memory & Block Size Tuning**
- [ ] Implement pinned memory allocations
- [ ] Automated block size search (128, 256, 512, 1024)
- [ ] Find optimal configuration

**Day 7: Profiling & Analysis**
- [ ] Fix GPU profiling permissions (reboot required)
- [ ] Run Nsight Compute profiling
- [ ] Analyze bottlenecks
- [ ] Identify next optimization targets

### Week 3: Advanced Optimizations (Optional)

**If we haven't hit 1B words/s yet:**
- [ ] Async streams for compute/transfer overlap
- [ ] Multi-GPU support (if available)
- [ ] Further kernel micro-optimizations

---

## Success Metrics

### Minimum Viable Target (MVP)
- **850M words/s** average across all patterns (+24% vs baseline)
- All patterns >800M words/s minimum
- CV remains <5% (stable performance)

### Stretch Goal
- **1B words/s** average (+46% vs baseline)
- Large pattern (8-char) >900M words/s
- Publication-quality results for academic paper

### Ultimate Goal
- **1.2B words/s** (approaching theoretical maximum)
- Multi-GPU scaling demonstrated
- Industry-leading wordlist generation performance

---

## Risk Mitigation

### Risk 1: Optimizations Don't Help
**Mitigation:** Benchmark after each change, use `scripts/compare_benchmarks.sh`
**Rollback:** Git branches for each optimization, easy to revert

### Risk 2: Correctness Regression
**Mitigation:** Run cross-validation after every kernel change
**Test:** `cargo test && cargo run --example cross_validate`

### Risk 3: Performance Regression
**Mitigation:** Always compare with baseline before committing
**Alert:** If CV increases >5%, investigate instability

---

## Analytical Optimization (No Profiling Needed)

While waiting for profiling permissions, we can start with **analytical optimization**:

### Current Kernel Analysis (wordlist_poc.cu:44-46)

```cuda
int char_idx = remaining % cs_size;        // ‚Üê EXPENSIVE (div hardware)
word[pos] = charset_data[cs_offset + char_idx];
remaining /= cs_size;                      // ‚Üê EXPENSIVE (div hardware)
```

**Problem:**
- Integer division/modulo on GPU: 20-40 cycles (very slow!)
- Per-character overhead: ~60-80 cycles just for arithmetic
- 8-character word: 480-640 cycles just for div/mod
- This is 70-80% of kernel runtime!

**Solution (Barrett Reduction):**
- Replace with multiplication + shift: 4-6 cycles
- Speedup: 5-10x faster arithmetic
- Expected kernel speedup: 2-3x total

### Why Barrett Works

Instead of:
```
q = x / m
r = x % m
```

Barrett precomputes:
```
m_inv = (2^64) / m  (computed once on CPU)
```

Then on GPU:
```
q_approx = (x * m_inv) >> 64   // Fast!
r = x - q_approx * m           // Fast!
```

**Tradeoff:** Slight approximation, but exact for our use case (32-bit charset sizes)

---

## Next Actions

### Immediate (No reboot required):
1. ‚úÖ Create Phase 3 tracking document (this file)
2. ‚è≠Ô∏è Implement Barrett reduction (Priority 1)
3. ‚è≠Ô∏è Implement power-of-2 fast path
4. ‚è≠Ô∏è Benchmark improvements

### After reboot (for profiling):
1. Apply NVIDIA profiling permission fix
2. Run `./scripts/profile_kernel.sh`
3. Analyze results with Nsight Compute
4. Refine optimization priorities based on data

---

## Documentation Updates

As we complete optimizations:
- [ ] Update `docs/DEVELOPMENT_LOG.md` with Phase 3 progress
- [ ] Document each optimization in detail
- [ ] Update `docs/TODO.md` Phase 3 checklist
- [ ] Create memory entries after milestones
- [ ] Update baseline benchmarks: `benches/scientific/results/phase3_*.json`

---

## References

### Barrett Reduction
- [Fast Division Algorithm](https://en.wikipedia.org/wiki/Barrett_reduction)
- [GPU-Optimized Barrett](https://github.com/zwegner/faster-integer-division)

### CUDA Optimization
- [CUDA Best Practices Guide](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/)
- [Occupancy Calculator](https://docs.nvidia.com/cuda/cuda-occupancy-calculator/)

### Nsight Compute
- [Profiling Guide](https://docs.nvidia.com/nsight-compute/ProfilingGuide/)
- [Metrics Reference](https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html)

---

**Document Version:** 1.0
**Last Updated:** November 17, 2025
**Next Update:** After Week 1 optimizations complete
